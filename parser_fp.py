import aiohttp
from bs4 import BeautifulSoup
from loguru import logger
import re
from collections import Counter
from enums.enums import Data
import asyncio
import random

logger.add("tgbot.log", format="{time} | {level} | {message}", level="INFO")

class Parser:
    def __init__(self):
        pass

    async def fetch_user_data(self, user_id):
        """
        –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        """
        url = f"https://funpay.com/users/{user_id}/"
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=5), ssl=False) as response:
                    response.raise_for_status()
                    return await response.read()
        except aiohttp.ClientError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {e}")
            return None


    async def parse_reviews_count(self, soup):
        """
        –ø–∞—Ä—Å–∏—Ç –∫–æ–ª-–≤–æ –æ—Ç–∑—ã–≤–æ–≤
        """
        for element in soup.find_all(class_=["rating-full-count", "text-mini text-light mb5"]):
            text = element.get_text(strip=True).replace("–í—Å–µ–≥–æ ", "").replace("–æ—Ç–∑—ã–≤", "").replace('–∞', '').replace('–æ–≤', '')
            if text.isdigit():
                return text
        return "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def parse_most_popular_game4reviews(self, soup):
        """
        —Å–∞–º—ã–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –∏–≥—Ä—ã –ø–æ –æ—Ç–∑—ã–≤–æ–≤ #TODO –ø–∞—Ä—Å–∏—Ç 25 –æ—Ç–∑—ã–≤–æ–≤, –∞ –∏ —Ç–æ –º–µ–Ω—å—à–µ, —á–µ–º –Ω–∞–¥–æ, —Ñ–∏–∫—Å–∏—Ç–±
        """
        games = [element.find("div", {"class": "review-item-detail"}).text.strip().split(",")[0].strip() for element in soup.find_all("div", {"class": "review-item-user"})]
        game_popularity = Counter(games)
        top_games = game_popularity.most_common(3)

        return '\n'.join([f"{game[0]} - {game[1]}" for game in top_games])

    async def parse_username(self, soup):
        """
        –ø–∞—Ä—Å–∏—Ç –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        element = soup.select_one(".mr4")
        return element.text.strip() if element else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def parse_estimation(self, soup):
        """—Ä–µ–π—Ç–∏–Ω–≥"""
        element = soup.select_one(".big")
        return element.text.strip() if element else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def parse_registration_date(self, soup):
        """–¥–∞—Ç—É —Ä–µ–≥–µ—Å—Ç—Ä–∞—Ü–∏–∏"""
        text = next((element.text.split(), ["–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"])[0] for element in (soup.find("div", {"class": "text-nowrap"}),))
        return ' '.join([text[0], text[1], text[2]])

    async def parse_offers_count(self, soup):
        """
        –ø–∞—Ä—Å–∏—Ç –∫–æ–ª-–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–∫–∞—Ç–µ–≥–æ—Ä–∏–π/–∏–≥—Ä)
        """
        return len(soup.select(".offer")) - 1 #1 offer —ç—Ç–æ –æ—Ç–∑—ã–≤—ã))

    async def parse_lot_count(self, soup):
        """
        –ø–∞—Ä—Å–∏—Ç –∫–æ–ª-–≤–æ –ª–æ—Ç–æ–≤
        """
        return len(soup.select(".tc-item"))

    async def parse_status(self, soup):
        """—Å—Ç–∞—Ç—É—Å"""
        element = soup.select_one(".media-user-status")
        return element.text.strip() if element else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def parse_price(self, soup):
        """
        –ø–∞—Ä—Å–∏—Ç —Ü–µ–Ω—É –ª–æ—Ç–æ–≤
        """
        max_price = -1
        max_price_link = None
        
        for element in soup.find_all("a", class_="tc-item"):
            price_lot = element.find("div", class_="tc-price", recursive=False)
            if price_lot and "sort" not in price_lot.get("class", []):
                try:
                    price = float(price_lot.get_text(strip=True).replace(' ', '').replace(',', '.').replace('‚ÇΩ', ''))
                    if price > max_price:
                        max_price = price
                        max_price_link = element.get("href")
                except ValueError:
                    logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã: {price_lot.get_text(strip=True)}")
        
        return (max_price, max_price_link) if max_price != -1 else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"

    async def parse_avatar(self, soup):
        """–∞–≤–∞—Ç–∞—Ä–∫–∞"""
        avatar_photo = soup.select_one(".avatar-photo[style]")
        if avatar_photo:
            return re.search(r"url\((.*?)\)", avatar_photo["style"]).group(1).strip('"')

    async def parse_last_review(self, soup):
        """–ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç–∑—ã–≤"""
        review_container = soup.find("div", {"class": "review-container"})
        if review_container:
            lines = [line.strip() for line in review_container.text.strip().splitlines() if line.strip()]
            return f"–î–∞—Ç–∞ –Ω–∞–ø–∏—Å–∞–Ω–∏—è: {lines[0]}, –ò–≥—Ä–∞ –∏ —Ü–µ–Ω–∞: {lines[1]}, –û—Ç–∑—ã–≤: {' '.join(lines[2:])}" if len(lines) > 2 else "–ù–µ—Ç –æ—Ç–∑—ã–≤–æ–≤"
        return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ"

    async def parse_average_price(self, soup):
        """–ø–∞—Ä—Å —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã (–ø—Ä–∞–π—Å –≤—Å–µ—Ö –ª–æ—Ç–æ–≤ / –∫–æ–ª-–≤–æ –ª–æ—Ç–æ–≤)"""
        prices_list = []

        for element in soup.find_all("a", {"class": 'tc-item'}):
            price_lot = element.find("div", class_="tc-price")
            
            if price_lot and "sort" not in price_lot.get("class", []):
                try:
                    price = float(price_lot.get_text(strip=True).replace(' ', '').replace(',', '.').replace('‚ÇΩ', ''))
                    prices_list.append(price)

                except ValueError:
                    logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã: {price_lot.get_text(strip=True)}")

        if prices_list:
            average_price = sum(prices_list) / len(prices_list)
            average_price = round(average_price, 2)
            
            return average_price
        else:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ü–µ–Ω—ã –≤ —Ä–∞–∑–¥–µ–ª–µ.")

    async def parse_auto_lots(self, soup):
        """–ø–∞—Ä—Å –ª–æ—Ç–æ–≤ —Å –∞–≤—Ç–æ–≤—ã–¥–∞—á–µ–π"""
        return len(soup.select(".sc-offer-icons"))

    async def mansory_check(self, soup):
        """–ø–∞—Ä—Å–∏—Ç –µ—Å—Ç—å –ª–∏ —Ä—É–±–ª–µ–≤–∫–∏ –º–∞–Ω—Å–æ—Ä–∏"""
        async for lot_id, name, price in self.parse_lots4prices(soup):
            if name.startswith("üíé–ê–í–¢–û–í–´–î–ê–ß–êüíé üî•8 Ball Pool: –ì–∞–π–¥ –¥–ª—è –Ω–æ–≤–∏—á–∫–æ–≤üî•") or "üíé–ê–í–¢–û–í–´–î–ê–ß–êüíé" in name:
                return True
        
        return False

    async def parse_lots4prices(self, soup):
        """–ø–∞—Ä—Å –ª–æ—Ç–æ–≤ —Å —Ü–µ–Ω–∞–º–∏"""
        lot_elements = soup.select("a.tc-item[href*='funpay.com/lots/offer?id=']")
        for element in lot_elements[:20]:
            lot_id = element["href"].split("funpay.com/lots/offer?id=", 1)[1]
            name = element.select_one(".tc-desc-text").text.strip()
            price = element.select_one(".tc-price").text.strip()

            yield lot_id, name, price

    async def check_banned(self, soup):
        """–ø–∞—Ä—Å–∏—Ç –∑–∞–±–∞–Ω–µ–Ω –ª–∏ —é–∑–µ—Ä"""
        banned_element = soup.select_one(".user-badges")
        if banned_element and banned_element.text == "–∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω":
            return True

        return False

    async def fetch_lot_data(self, session, lot_url):
            """–ó–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ –ª–æ—Ç—É –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
            try:
                async with session.get(lot_url, ssl=False) as response:
                    response.raise_for_status()
                    html_response = await response.text()

                soup = BeautifulSoup(html_response, "html.parser")
                cat_name = soup.find("span", class_="inside").text
                stars = soup.find("span", class_="big").text

                logger.info(type(stars))
                logger.info(f"Stars: {stars} Category: {cat_name}")
                if '.' in stars:
                    logger.info("returning" )
                    return

                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–≤—ë–∑–¥ –º–µ–Ω—å—à–µ 5
                if int(stars) < 5:
                    logger.info(f"Stars: {stars} Category: {cat_name} ening")
                    return [stars, cat_name]
            except Exception as e:
                logger.error(f"Error fetching {lot_url}: {e}")
            return None
        
    async def parse_category(self, session, category):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Å—ã–ª–∫–∏ –Ω–∞ –ø–µ—Ä–≤—ã–π –ª–æ—Ç –∏ –µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        try:
            lot_in_category = category.find("a", class_="tc-item")
            if lot_in_category:
                link_to_lot = lot_in_category.get("href")
                return await self.fetch_lot_data(session, link_to_lot)
        except Exception as e:
            logger.error(f"Error parsing category: {e}")
        return None
    
    async def sanction_check(self, soup):
        """–ü–∞—Ä—Å–∏—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–≤–µ–∑–¥ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫"""
        lst = []
        categories = soup.find_all("div", class_="offer")
        # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –±–æ–ª–µ–µ 30, —É–¥–∞–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏

        if len(categories) > 30:
            random_categories = random.sample(categories, 30)
            categories = random_categories

        # –°–æ–∑–¥–∞—ë–º —Å–µ—Å—Å–∏—é –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        async with aiohttp.ClientSession() as session:
            tasks = [self.parse_category(session, category) for category in categories]
            results = await asyncio.gather(*tasks)

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, —á—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ, –≥–¥–µ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        lst = [result for result in results if result]
        return lst

    async def parse_usr_data(self, user_id, lazy=False):
        html_response = await self.fetch_user_data(user_id)
        if html_response is None:
            return None
        
        soup = BeautifulSoup(html_response, "html.parser")
        ban = await self.check_banned(soup)
        if ban:
            return None
        
        if lazy:
            # –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            data = Data(
                await self.parse_username(soup),
                await self.parse_reviews_count(soup),
                await self.parse_estimation(soup),
                await self.parse_status(soup),
                None, None, None, None, None, None, None, None, None, f"https://funpay.com/users/{user_id}/"
            )
        else:
            # –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            data = Data(
                await self.parse_username(soup),
                await self.parse_reviews_count(soup),
                await self.parse_estimation(soup),
                await self.parse_registration_date(soup),
                await self.parse_offers_count(soup),
                await self.parse_last_review(soup),
                await self.parse_lot_count(soup),   
                await self.parse_status(soup),
                *(await self.parse_price(soup)),
                await self.parse_average_price(soup),
                await self.parse_avatar(soup),
                await self.parse_most_popular_game4reviews(soup),
                await self.mansory_check(soup),
                await self.parse_auto_lots(soup),
                f"https://funpay.com/users/{user_id}/",
                await self.sanction_check(soup)
            )
            
        return data